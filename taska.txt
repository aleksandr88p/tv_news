что мне надо сделать
из некоторых источников спарсить статьи, хранить их в бд, после этого обработать перед использованием
chatGPT, после этого как то предоставлять заказзчику сводку по новостям
https://www.hollywoodreporter.com
The Hollywood Reporter (Film News, and TV News)

https://variety.com
Variety (Film News, and TV News)

https://www.indiewire.com
IndieWire (Film and TV)

https://deadline.com
Deadline (Film and TV)


Скрапинг данных:
для начала напишу скрипты для извлечения статей. Попробую для начала использовать просто requests или aiiohttp(если
нужна будет ассинхронность) попробую сначала все это делать без использования прокси серверов, надеюсь не будет блокировок
Нужно сделать первый запрос, что бы посмотерть и сохранить ссылки на статьи. Так что я думаю на этом этапе записывать
в первую таблицу, заголовок и ссылку на статью


Хранение данных:
буду хранить статьи в БД(mysql или postgresql)
планирую сделать одну БД, и одну таблицу для каждого источника с колонками (дата новости, источник, статья и т.д.)

Обработка данных:
возможно придется обработать статьи перед использованием в chatGPT,это может включать в себя очистку текста,
такую как удаление специальных символов, ссылок или другого несущественного содержания.
библиотеки NLP, такие как NLTK или Spacy.

Использование ChatGPT для создания сводок: Затем использовать ChatGPT для создания сводок для каждой статьи.
Это можно сделать, используя API предложенное OpenAI,
и передавая текст статьи в качестве ввода для получения краткого содержания.

Компиляция и представление данных: Последним шагом будет компиляция сводок в единый дайджест и
представление этого дайджеста в удобном для чтения формате. например,
создать веб-страницу с помощью библиотеки Flask, чтобы представить эти сводки.

Автоматизация: Весь этот процесс можно автоматизировать,
используя cronjobs (если вы используете Unix-подобную операционную систему)
или с помощью Task Scheduler (для Windows). Вы можете настроить эту работу, чтобы выполняться каждый день в определенное время.


я думаю весь этот проект написать в fast api
у меня там надо парсить около 8 страниц.
1) Как мне в структуре fastApi это сделать. Типа в главный файл импортировать мои парсеры,
2) а как авмтоматизировать мою апишку. типа что бы каждый час парсил




Processing articles from Deadline...
Connect to mysql successful
For deadline_film: Added 2 new articles, Found 10 duplicate articles
For deadline_tv: Added 0 new articles, Found 12 duplicate articles
Processing articles from Hollywood Reporter...
Connect to mysql successful
For hollywoodreporter_movies_news: Added 0 new articles, Found 16 duplicate articles
For hollywoodreporter_tv_news: Added 0 new articles, Found 16 duplicate articles
Processing articles from Indiwire...
Connect to mysql successful
error 'NoneType' object has no attribute 'find'
cant find title in https://www.indiewire.com/video/lesli-linka-glatter-on-hbos-love-and-death-1234867332/
error 'NoneType' object has no attribute 'find'
cant find artcicle in https://www.indiewire.com/video/lesli-linka-glatter-on-hbos-love-and-death-1234867332/
For indiwire_film: Added 12 new articles, Found 0 duplicate articles
For indiwire_tv: Added 12 new articles, Found 0 duplicate articles
Processing articles from Variety...
Connect to mysql successful
For variety_film_news: Added 15 new articles, Found 0 duplicate articles
For variety_tv_news: Added 15 new articles, Found 0 duplicate articles


